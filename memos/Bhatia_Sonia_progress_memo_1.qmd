---
title: "Progress Memo 1"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Sonia Bhatia"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---



::: {.callout-tip icon=false}

## Github Repo Link

To link to your github **repo**sitory, appropriately edit the example link below. Meaning replace `https://your-github-repo-url` with your github repo url. Suggest verifying the link works before submitting.

[https://github.com/stat301-2-2024-winter/final-project-2-soniab101](https://github.com/stat301-2-2024-winter/final-project-2-soniab101)

:::

::: {.callout-warning}
GitHub (free account) cannot store large files. If you try to commit and push a large dataset you will have an ERROR! Any file over 100 MB (100,000 KB) needs to be added to the `.gitignore` file BEFORE committing.

**We may need to do that for files in your final project!**
:::

## Prediction question
My prediction research question is can we predict the air quality on a certain day based off certain factors such as nitric oxide levels, nitric dioxide, and ammonia levels in the air. My variable of interest is air quality level (AQI variable), and this is a regression problem. I am interested in pursuing this problem because it has many important applications in areas of public health, environmental health, and urban development. For example, poor air quality can have severe health implications, especially for vulnerable populations such as children, the elderly, and those with respiratory conditions. Predicting air quality allows authorities to issue warnings and advisories, helping people take necessary precautions to protect their health.

## Data source

```{r}
#| echo: true
library(tidyverse)
library(naniar)
setwd("/Users/sonia/Desktop/STAT 301-2/final project/final-project-2-soniab101/memos")
air_data<- read_csv("city_day.csv")

```

I found this dataset on Kaggle titled 'Air Quality Data in India (2015-2020). The data has been compiled from the Central Pollution Control Board (CPCB) website: https://cpcb.nic.in/ which is the official body of Government of India. 
[Source: Found on Kaggle, linked here. Data is from: https://cpcb.nic.in/](https://www.kaggle.com/datasets/rohanrao/air-quality-data-in-india?select=city_day.csv)]



## Data quality & complexity check
```{r}
miss_var_summary(air_data)

gg_miss_var(air_data)
```


I have 16 variables in my dataset, and 29531 observations. There are 3 categorical variables, and 13 numerical variables. I do have missingness issues, as shown above. All the variables other than data and city are missing observations, however, for most variables they are just missing a small portion of their observations. However, I am missing almost 2/3 of the observations for the Xylene variables. Since my dataset is very large though, I do not believe this missing data will be a significant issue since I still have many data points. 

## Target variable analysis
```{r}
air_data |> ggplot(aes(x = AQI)) + geom_histogram(fill = "seagreen", color = "white", bins = 30) +
  scale_x_continuous(limits = c(0,1000)) +
  labs(title = "Air Quality in India", x = "Air Quality Index")


```

I noticed that the data is left skewed, meaning that the data may violate the assumption of normalcy that some statistical tests we may be interested in performing require. The left skewness also tells us that the median will be a better measure of central tendency than the mean for this dataset. To handle this data for our predictive modeling, it might be best to perform a log transformation to normalize the data. 

## Misc
I think I will need to plan for a good amount of time for data cleaning in relation to the missing data since quite a few observations are missing. I will make sure to leave adequate time for fitting and training my models since my dataset is very large, meaning that the run time could be high. 

